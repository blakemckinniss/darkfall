# Claude Code Hooks

This directory contains custom hooks for Claude Code that enforce project-specific policies and enhance the development workflow.

## Architecture: Shared Libraries

**NEW: Modular Design** - Hooks now use shared libraries to reduce code duplication and improve maintainability.

### Directory Structure
```
.claude/hooks/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ validation-common.sh      # Shared validation functions
‚îÇ   ‚îú‚îÄ‚îÄ pattern-detection.sh      # Task type and risk detection
‚îÇ   ‚îú‚îÄ‚îÄ typescript-checks.sh      # TypeScript/ESLint checking
‚îÇ   ‚îú‚îÄ‚îÄ task_classifier.py        # Fast task classification (NEW)
‚îÇ   ‚îî‚îÄ‚îÄ quick_tool_planner.py     # Tool planning pattern matcher (NEW)
‚îú‚îÄ‚îÄ prompt-validator.sh            # 350 lines (was 663) - uses shared libs
‚îú‚îÄ‚îÄ session-start.sh               # Uses inline functions
‚îú‚îÄ‚îÄ tool-planner.sh                # Tool planning hook (NEW - Phase 1 MVP)
‚îú‚îÄ‚îÄ pre-tool-pattern-prevention.sh # 122 lines
‚îú‚îÄ‚îÄ validate-directory-creation.sh # 52 lines
‚îú‚îÄ‚îÄ validate-markdown-creation.sh  # 147 lines
‚îú‚îÄ‚îÄ tool-awareness.py              # 48 lines
‚îú‚îÄ‚îÄ posttooluse-metacognition.py   # 474 lines
‚îî‚îÄ‚îÄ post-edit-format.sh            # 81 lines
```

### Shared Library Functions

**lib/validation-common.sh:**
- `check_prompt_quality()` - Detects vague prompts, suggests improvements
- `extract_mentioned_files()` - Extracts file paths for smart filtering
- `check_blocked_patterns()` - Validates against blocked patterns
- `get_block_reason()` - Returns standardized block messages

**lib/pattern-detection.sh:**
- `detect_task_type()` - Identifies bugfix/feature/refactor/performance tasks
- `get_tech_risk_database()` - Technology version risk database
- `detect_outdated_knowledge_risk()` - Warns about potentially outdated AI knowledge
- `check_doc_update_triggers()` - Suggests ADR.md/CLAUDE.md/NOTES.md updates

**lib/typescript-checks.sh:**
- `run_typescript_eslint_checks()` - Parallel TypeScript + ESLint checking with smart caching

### Performance Impact
- **Zero overhead**: Libraries are sourced once at hook startup
- **Reduced size**: prompt-validator.sh reduced from 663 to 350 lines (47% reduction)
- **Maintainability**: Shared code in one place (DRY principle)

## Hooks Overview

### 1. Tool Planning Hook (NEW - Phase 1 MVP)
**File**: `tool-planner.sh`
**Triggers**: UserPromptSubmit (after confidence-classifier)
**Purpose**: Generates strategic tool usage recommendations to optimize task execution

**How It Works:**
1. **Task Classification** - Reuses confidence system classification (atomic/routine/complex/risky/open_world)
2. **Conditional Execution** - Only runs planning for tasks that benefit from it
3. **Pattern Matching** - Detects parallelization, script opportunities, MCP tool usage, and agent delegation
4. **Strategic Guidance** - Provides advisory recommendations without restricting Claude's autonomy

**Performance Targets:**
- Atomic: 0s (skipped entirely)
- Routine: < 3s (fast pattern matching)
- Complex: < 7s (comprehensive patterns)
- Risky/Open World: < 15s (future: Zen MCP integration)

**Optimization Patterns Detected:**

‚ö° **Parallelization**
- Multiple file operations ‚Üí Suggests parallel Read calls
- Independent API calls ‚Üí Batch processing
- Example: "Refactor UserService.ts, AuthService.ts, DatabaseManager.ts"

üìù **Script Generation**
- Testing/validation keywords ‚Üí tmp-test-runner.sh
- Build operations ‚Üí tmp-build-script.sh
- Example: "Run tests and validate the authentication flow"

üîß **MCP Tool Selection**
- Open world research ‚Üí MANDATORY zen:chat with websearch
- Browser interaction ‚Üí MANDATORY playwright MCP
- Debugging ‚Üí zen:debug suggested
- Decisions ‚Üí zen:consensus suggested
- Code review ‚Üí zen:codereview suggested

ü§ñ **Agent Delegation**
- 3+ sequential tasks ‚Üí Parallel agent execution
- 5+ files modified ‚Üí Specialized agent suggestion
- Example: "Update user system then fix auth then update tests"

**Caching:**
- 5-minute TTL for similar prompts
- Reduces latency for repeated task patterns
- Automatically invalidated when needed

**Example Output:**
```
## üõ†Ô∏è Tool Strategy (Auto-Generated)

**Task Class:** complex | **Planning Tier:** 1 (local pattern matching)

**Recommended Optimizations:**
1. ‚ö° **Parallelization**: Files [UserService.ts, AuthController.ts] can be read simultaneously
2. ü§ñ **Agent**: Complex multi-file task (5 files) - consider Task tool with specialized agent

**Estimated Time Savings:** ~90s
**Confidence Boost:** +0.15 (via tooling_optimization_score)

**Execution Strategy:**
- Use single message with multiple tool calls for parallel operations
- Generate helper scripts for repeated operations
- Consult appropriate MCP tools when needed
```

**Implementation Details:**
- **Library Files:**
  - `lib/task_classifier.py` - Fast task classification (< 50ms)
  - `lib/quick_tool_planner.py` - Pattern matching and plan generation
- **Future Phases:**
  - Phase 2: Zen MCP integration for deep planning on risky/open_world tasks
  - Phase 3: Learning loop to improve recommendations based on outcomes

**Disabling:**
To disable tool planning, comment out the hook in `.claude/settings.json`:
```json
// {
//   "type": "command",
//   "command": "\"$CLAUDE_PROJECT_DIR\"/.claude/hooks/tool-planner.sh",
//   "timeout": 15
// }
```

### 2. Directory Creation Validation
**File**: `validate-directory-creation.sh`
**Triggers**: PreToolUse (directory creation)
**Purpose**: Requires AI justification and user approval before creating new directories

### 2. Markdown File Creation Restriction
**File**: `validate-markdown-creation.sh`
**Triggers**: PreToolUse (Write tool, Bash commands)
**Purpose**: Restricts markdown file creation to specific whitelisted locations, with special handling for README.md
**Policy**:
- ‚úÖ Allows: `/docs` directory, hidden directories (`.claude`, `.github`, etc.), `CLAUDE.md` anywhere
- ‚ùå Blocks: All other `.md` files outside whitelisted locations
- ‚õî **README.md**: Specifically blocked with educational message suggesting CLAUDE.md instead

### 3. Session Start Context
**File**: `session-start.sh`
**Triggers**: SessionStart
**Purpose**: Provides project status, dependency checks, optional health validation, and development guidelines
**Portability**: Fully project-agnostic - auto-detects Node.js, Python, Go, Rust, Ruby, Java projects

### 4. Prompt Validation & Documentation Tracking
**File**: `prompt-validator.sh`
**Triggers**: UserPromptSubmit
**Purpose**: Validates prompts, enforces task requirements, and monitors documentation updates

---

## Markdown File Creation Restriction Hook

**File**: `validate-markdown-creation.sh`

### Purpose
Enforces a strict policy preventing markdown file proliferation outside designated documentation areas.

### Policy Rules

‚úÖ **Allowed Locations:**
- `/docs` directory and subdirectories - For all project documentation
- Hidden directories (starting with `.`) - `.claude`, `.github`, `.vscode`, etc.
- `CLAUDE.md` file - Allowed in any location (scoped project instructions)
  - **Pro tip**: Use subdirectory CLAUDE.md files for area-specific guidance
  - Works like inheritance: root CLAUDE.md = baseline, subdirs add/override specifics
  - Example: `components/CLAUDE.md` for component conventions, `api/CLAUDE.md` for API rules

‚ùå **Blocked Locations:**
- Root directory (except `CLAUDE.md`)
- Component directories (`/components`, `/lib`, `/app`, etc.)
- Any non-whitelisted location

### How It Works

1. **Triggers On**:
   - `Write` tool calls creating `.md` files
   - `Bash` tool calls containing markdown file creation (touch, echo >, cat >, etc.)

2. **Behavior**:
   - Checks file path against whitelist rules
   - Returns `"ask"` permission decision for restricted files
   - Shows user clear policy explanation

3. **User Action Required**:
   - Review the blocked markdown file path
   - The hook suggests creating `CLAUDE.md` in that specific directory
   - Consider these alternatives:
     - Move documentation to `/docs` directory
     - Create `CLAUDE.md` in the target directory (scoped guidance, no conflicts)
     - Use hidden directories for tooling configs

### Example Flows

**README.md Blocking (Special Case):**
```
Claude: "I'll create a README.md in the root directory."
[Hook triggers]
User sees: "‚õî README.md Creation Blocked
            üö´ README.md files are not allowed in this project.
            üí° Use CLAUDE.md instead:
               ‚Ä¢ CLAUDE.md is the standard for Claude Code projects
               ‚Ä¢ Hierarchical: Root CLAUDE.md = baseline, subdirs add specifics
               ‚Ä¢ Auto-discovered by Claude when working in this area
            üìö Why CLAUDE.md over README.md?
               ‚Ä¢ Directly read by Claude Code for context and guidelines
               ‚Ä¢ Supports inheritance (root + subdirectory combined)
               ‚Ä¢ Better separation: CLAUDE.md = AI guidance, docs/ = human docs"
User: "Got it! Please create/update CLAUDE.md instead"
Claude: "I'll update CLAUDE.md with the project information"
[Hook allows] ‚úì (CLAUDE.md allowed anywhere)
```

**Other Markdown Files:**
```
Claude: "I'll create a guide.md in the components folder."
[Hook triggers]
User sees: "‚õî Markdown File Creation Restricted
            üí° Consider: Create CLAUDE.md in this directory (components/CLAUDE.md)
               ‚Üí Provides scoped guidance for this area
               ‚Üí Won't conflict with root CLAUDE.md (works like inheritance)"
User: "Please create components/CLAUDE.md instead"
Claude: "I'll create components/CLAUDE.md with component-specific guidelines"
[Hook allows] ‚úì (CLAUDE.md allowed anywhere)
```

### Testing

Test the hook manually:
```bash
# Should block with README.md-specific message
echo '{"tool_name": "Write", "tool_input": {"file_path": "/project/README.md"}}' | \
  ./.claude/hooks/validate-markdown-creation.sh

# Should block with general markdown message
echo '{"tool_name": "Write", "tool_input": {"file_path": "/project/guide.md"}}' | \
  ./.claude/hooks/validate-markdown-creation.sh

# Should allow
echo '{"tool_name": "Write", "tool_input": {"file_path": "/project/CLAUDE.md"}}' | \
  ./.claude/hooks/validate-markdown-creation.sh

echo '{"tool_name": "Write", "tool_input": {"file_path": "/project/docs/guide.md"}}' | \
  ./.claude/hooks/validate-markdown-creation.sh
```

---

## Directory Creation Hook

**File**: `validate-directory-creation.sh`

### Purpose
Enforces a policy requiring AI justification and user approval before creating new directories.

### How It Works

1. **Triggers On**:
   - `mcp__filesystem__create_directory` tool calls
   - `Bash` tool calls containing `mkdir` commands

2. **Behavior**:
   - Intercepts directory creation requests
   - Returns `"ask"` permission decision
   - Shows user a prompt requiring verification that Claude has:
     - Explained WHY the directory is needed
     - Described what will be stored in it
     - Confirmed it doesn't duplicate existing structure

3. **User Action Required**:
   - When prompted, review Claude's most recent message
   - Verify Claude provided adequate justification
   - Approve if justified, deny if not
   - If denied, ask Claude to explain before retrying

### Example Flow

```
Claude: "I'll create a new directory for test fixtures."
[Hook triggers]
User sees: "‚ö†Ô∏è Directory Creation Requires Approval
            Before approving, verify Claude has explained WHY..."
User reviews Claude's message, sees insufficient justification
User: Denies request, asks "Please explain why we need this directory"
Claude: "We need this directory to store JSON test fixtures for..."
[Hook triggers again]
User: Reviews explanation, approves
Directory created ‚úì
```

### Configuration

The hook is configured in `.claude/settings.json`:

```json
{
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "mcp__filesystem__create_directory",
        "hooks": [...]
      },
      {
        "matcher": "Bash",
        "hooks": [...]
      }
    ]
  }
}
```

### Testing

Test the hook manually:
```bash
echo '{"tool_name": "mcp__filesystem__create_directory", "tool_input": {"path": "/test"}}' | \
  ./.claude/hooks/validate-directory-creation.sh
```

### Notes

- Hook changes require Claude Code restart to take effect
- Check `/hooks` menu in Claude Code to verify hook is registered
- Use `claude --debug` to see detailed hook execution logs

---

## Session Start Context Hook

**File**: `session-start.sh`

### Purpose
Provides intelligent project status information at session start, including environment validation, dependency checking, and development guidelines.

### Key Features

#### 1. Multi-Language Dependency Detection
Automatically detects project type and verifies dependencies:

**Supported Languages/Frameworks:**
- **Node.js/TypeScript** - Detects pnpm/yarn/npm and checks for node_modules
- **Python** - Checks for venv/.venv with pipenv/poetry/pip support
- **Go** - Verifies go command and go.mod
- **Rust** - Checks for cargo command and Cargo.toml
- **Ruby** - Detects Gemfile and bundle status
- **Java Maven** - Checks for mvn command and pom.xml
- **Java Gradle** - Verifies gradle/gradlew and build files

**Example Output:**
```
## Project Status
Git: On branch 'main' with 5 uncommitted change(s)
‚ö†Ô∏è  Node.js project: node_modules not found. Run 'pnpm install'
```

#### 2. Optional Health Checks
If a custom health check script exists at `.claude/tests/health-check.sh`, it will be executed automatically:

```bash
## üîç Project Health Check
Running custom health validation...
‚úÖ Health check passed
```

**Creating a Custom Health Check:**
```bash
#!/bin/bash
# .claude/tests/health-check.sh

# Example: Check if API keys are configured
if [ -z "$API_KEY" ]; then
  echo "Error: API_KEY environment variable not set"
  exit 1
fi

# Example: Check if services are running
if ! curl -s "http://localhost:3000" > /dev/null; then
  echo "Error: Development server not running"
  exit 1
fi

echo "All health checks passed"
exit 0
```

#### 3. Development Guidelines Integration
- If `CLAUDE.md` exists: References it for project-specific guidelines
- If no `CLAUDE.md`: Shows generic best practices

This makes the hook work in any project while allowing customization.

#### 4. Environment Variable Loading
Automatically loads `.env` file if present and `CLAUDE_ENV_FILE` is set.

#### 5. Mandatory Playwright MCP Usage Directive
Displays critical reminder at session start requiring Playwright MCP tools for all website interactions:

**Output Displayed:**
```
üö® **MANDATORY PLAYWRIGHT MCP USAGE POLICY** üö®

**WHEN INTERACTING WITH ANY WEBSITE, YOU MUST USE PLAYWRIGHT MCP TOOLS**

1. **NEVER use WebFetch/WebSearch** for website interaction (browsing, testing, forms, buttons)
2. **ALWAYS use Playwright MCP** (mcp__playwright__*) for ALL browser-based interactions
3. **This directive overrides all other considerations** - even if WebFetch seems simpler
4. **WebFetch ONLY for**: API docs, technical articles, library documentation (non-interactive)

**Why**: Playwright provides real browser context, JavaScript execution, console logs, screenshots, and proper interaction testing.
```

**Purpose**: Prevents common mistakes where Claude might attempt to use WebFetch for interactive website tasks instead of proper browser automation tools.

### Portability

**100% Project-Agnostic** - Works across:
- All programming languages (Node.js, Python, Go, Rust, Ruby, Java, etc.)
- All package managers (npm, yarn, pnpm, pip, poetry, cargo, bundle, maven, gradle)
- Any project structure
- With or without CLAUDE.md

**No Configuration Required** - Just copy the file to any project's `.claude/hooks/` directory.

### Customization Options

#### Add New Language Support
Edit the `detect_and_check_dependencies()` function:

```bash
# PHP / Composer
if [ -f "$CLAUDE_PROJECT_DIR/composer.json" ]; then
  if [ ! -d "$CLAUDE_PROJECT_DIR/vendor" ]; then
    dep_warnings+="‚ö†Ô∏è  PHP project: dependencies not found. Run 'composer install'"$'\n'
  fi
fi
```

#### Adjust Detection Logic
Modify thresholds or add custom checks within the function blocks.

#### Rename Health Check Script
Change line 118: `HEALTH_SCRIPT="$CLAUDE_PROJECT_DIR/.claude/tests/your-script.sh"`

---

## Prompt Validation & Documentation Tracking Hook

**File**: `prompt-validator.sh`

### Purpose
Validates user prompts, enforces task completion requirements, and automatically reminds Claude to check if documentation files need updates.

### Documentation Update Monitoring

The hook monitors for changes that likely affect these key files:

#### docs/ADR.md (Architecture Decision Records)
**Trigger Keywords**: architecture, state management, api design, database, deployment, build system, integration pattern, design pattern

**When to Update**:
- New architectural patterns introduced
- State management approach changes
- API design decisions
- Database schema or persistence changes
- Build/deploy process modifications
- Major integration decisions

#### CLAUDE.md (Development Guidelines)
**Trigger Keywords**: typescript config, dev command, workflow, slash command, hook, build process, lint rule, prettier, tsconfig

**When to Update**:
- New development commands added
- TypeScript configuration changes
- New slash commands created
- Hook modifications
- Build process updates
- Linting/formatting rule changes
- Project guideline additions

#### docs/NOTES.md (Critical Items Log)
**Trigger Keywords**: critical, urgent, blocker, high priority, must fix, breaking change

**Auto-Logging Behavior**:
- Items with üî¥76-100 (documentation updates)
- Items with üî¥76-100 (technical debt)
- Items with ‚≠ê76-100 (next steps)
- Appended with timestamp in format: `## YYYY-MM-DD HH:MM - [DOCS|DEBT|NEXT]`

**Manual Cleanup**:
- Use `/notes:cleanup` command to review and remove completed items
- Automated cleanup disabled due to performance constraints

### Task Completion Requirements

The hook enforces mandatory completion requirements for every task:

1. **Initial Confidence (0-100%)** - Stated before starting
2. **Final Confidence (0-100%)** - Stated after completion
3. **Documentation Updates Required** - First mandatory section
4. **Technical Debt & Risks** - Second mandatory section
5. **Next Steps & Considerations** - Third mandatory section
6. **Auto-Logging** - Critical items (76-100) automatically logged to NOTES.md
7. **Performance Optimization** - Parallel execution and batching encouraged

### Critical Reflection Questions

The hook generates **exactly 3 dynamic questions** tailored to:
- Task type (bugfix, feature, refactor, performance)
- Project state (uncommitted changes, critical backlog items)
- Prompt context (UI/UX, API integration, state management, TypeScript)

**Question 1 - Task-Specific:**
- **Bugfix**: Root cause analysis vs symptom treatment
- **Feature**: Alignment with core project goals and scope
- **Refactor**: Value vs effort trade-off assessment
- **Performance**: Measurement and profiling before optimization
- **General**: Task clarity and requirement validation

**Question 2 - Project Health:**
- Uncommitted changes warning (>15 files)
- Critical backlog items from NOTES.md (>5 items)
- Side effects and testing strategy
- Integration risk with existing systems

**Question 3 - Context-Aware:**
- **Browser/Website Interaction**: Playwright MCP usage verification (triggered by: website, browser, webpage, web app, navigate, click, form, button, playwright, screenshot, scrape, crawl, dom, element, selector, input field, submit, login page, headless, automation)
- **UI/UX**: User experience and design consistency
- **API Integration**: Rate limits, costs, fallback behavior
- **State Management**: Migration strategy and backward compatibility
- **TypeScript**: Type safety and compliance with strict mode
- **Default (rotating)**: Code maintainability, system scalability, cross-platform compatibility, performance implications

These questions rotate based on current hour to ensure variety across sessions.

#### Portability

The hook is **fully project-agnostic** and can be used in any codebase without modification. Questions are intentionally generic to work across:
- Web applications, mobile apps, APIs, CLIs
- Any programming language or framework
- Frontend, backend, full-stack, or infrastructure projects

If you want to customize questions for domain-specific terminology, edit the prompt text in `prompt-validator.sh`:
- Question 1: Task-type specific prompts (lines 238-248)
- Question 2: Project health checks (lines 251-270)
- Question 3: Context-aware prompts (lines 273-300)

### Smart Features

- **Task Type Detection**: Automatically detects bugfix, feature, refactor, performance tasks
- **Context Filtering**: Shows only relevant TypeScript/lint errors for modified files
- **Caching**: Skips type/lint checks if run within 60s with no file changes
- **Parallel Execution**: Runs TypeScript and ESLint checks simultaneously (2x speedup)
- **Prompt Quality Analysis**: Warns about vague prompts and suggests improvements

### Practical Development Hygiene Reminders

Beyond the 3 critical reflection questions, the hook provides additional context-aware reminders for common quality and portability issues:

#### Configuration/Portability Check
**Trigger Keywords**: hardcoded, localhost, 127.0.0.1, absolute path, /Users/, C:\\, api.*url.*http, endpoint.*=.*http, .env, API_KEY, SECRET

**Warning Displayed**:
```
‚öôÔ∏è **Configuration Check**: Hardcoded values detected. Use environment variables or config files for portability across environments.
```

**Purpose**: Catches hardcoded URLs, paths, and secrets that would break portability or cause "works on my machine" issues. Encourages proper configuration management without security theatre.

**Example Triggers**:
- "Set the API endpoint to http://localhost:3000"
- "Use absolute path /Users/john/project"
- "Add API_KEY = 'abc123' to the file"

#### Testing Discipline Reminder
**Trigger Keywords**: add.*(function|method|component|service|endpoint), new.*(function|component|service|class), create.*(function|component|service|api), implement.*(function|method|feature|endpoint), build.*(feature|service|component)

**Warning Displayed**:
```
üß™ **Testing Discipline**: New code detected. Consider test cases, edge cases, and validation strategy.
```

**Purpose**: Builds testing habit by reminding about test planning when new code is being added. Focuses on thinking through edge cases and validation, not coverage metrics or TDD dogma.

**Example Triggers**:
- "Add a new function for user authentication"
- "Implement a new endpoint for payment processing"
- "Create a service to handle file uploads"
- "Build a feature for real-time notifications"

#### Error Handling Awareness
**Trigger Keywords**: fetch, axios, api.*call, http.*request, database.*query, file.*read, file.*write, async, await, promise, external.*service, network.*request, third.*party

**Warning Displayed**:
```
üõ°Ô∏è **Error Handling**: External operations can fail. Plan for network errors, timeouts, and unexpected responses.
```

**Purpose**: Encourages resilient code by reminding about error handling when working with external operations. Focuses on thinking through failure modes, not defensive programming paranoia.

**Example Triggers**:
- "Add a fetch call to the API endpoint"
- "Query the database for user records"
- "Make an HTTP request to external service"
- "Use async/await to load file data"

#### Breaking Change Warning
**Trigger Keywords**: change.*(type|interface|schema|api|contract), modify.*(api|interface|schema|signature), rename.*(field|prop|property|column|method|function), remove.*(field|prop|property|column|endpoint), update.*(interface|type|schema|api), deprecate, breaking

**Warning Displayed**:
```
‚ö†Ô∏è **Breaking Change**: API/interface modification detected. Consider versioning, migration path, and backwards compatibility.
```

**Purpose**: Risk management for API/interface changes. Reminds about impact on existing consumers and migration planning, not bureaucratic change control.

**Example Triggers**:
- "Rename the userId field to accountId"
- "Change the response type from string to object"
- "Remove the deprecated endpoint"
- "Update the API interface to use new schema"

#### Performance Consciousness
**Trigger Keywords**: map.*map, nested.*loop, loop.*loop, forEach.*forEach, \.map.*\.filter, \.filter.*\.map, recursive.*call, n\+1, query.*all, fetch.*all.*records, load.*entire

**Warning Displayed**:
```
‚ö° **Performance**: Nested iterations or bulk operations detected. Consider data structure optimization, pagination, or lazy loading.
```

**Purpose**: Encourages algorithmic thinking when nested operations are detected. Focuses on considering alternatives, not premature optimization.

**Example Triggers**:
- "Use map followed by another map"
- "Nested loop to process all items"
- "Query all records from the database"
- "Filter then map the entire dataset"

**Philosophy**: These reminders are **practical nudges**, not bureaucratic requirements. They catch common mistakes early and encourage good development hygiene without being preachy or dogmatic.

### Example Output

When you submit a prompt containing "integrate with payment API", the hook will output:

```
üìã Reminder: Changes to architecture/design patterns may require docs/ADR.md update

## üéØ Task Completion Requirements (MANDATORY)
[Full requirements displayed with documentation update guidelines]

---

## üí≠ Critical Reflection Questions (MANDATORY)

Before proceeding, consider these questions:

1. **Clarity Check**: Is the task clearly defined, or should you ask clarifying questions before proceeding?
2. **Integration Risk**: How does this interact with existing systems and data flows?
3. **External Dependencies**: Are you considering rate limits, costs, and fallback behavior if external services fail?
```

**Note**: Questions dynamically adapt based on task type, project state, and prompt keywords. The hook works out-of-the-box for any project without customization.

### Configuration

Configured in `.claude/settings.json` under UserPromptSubmit hook. No user action required - the hook automatically injects context into every prompt submission.

---

## Question Quality Monitoring

### Purpose
Track the effectiveness of Critical Reflection Questions generated by `prompt-validator.sh` to identify areas for improvement.

### Monitoring Approach

#### 1. Manual Observation (Ongoing)
As you use Claude Code over multiple sessions, pay attention to:
- **Relevance**: Do the questions address actual concerns for the task?
- **Actionability**: Do the questions help you think through important aspects?
- **False Positives**: Are questions triggered unnecessarily?
- **False Negatives**: Are important concerns missed?

#### 2. Question Categories to Monitor

**Task-Specific Questions (Question 1)**
- Bugfix: "Root cause vs symptoms" - Does this prevent surface-level fixes?
- Feature: "Scope alignment" - Does this prevent scope creep?
- Refactor: "Value vs effort" - Does this prevent premature optimization?
- Performance: "Measurement first" - Does this encourage profiling?

**Project Health Questions (Question 2)**
- Uncommitted changes warning (>15 files) - Is threshold appropriate?
- Critical backlog (>5 NOTES.md items) - Is this useful?
- Side effects check - Does this catch integration issues?
- Testing strategy - Does this improve test coverage?

**Context-Aware Questions (Question 3)**
- UI/UX prompts ‚Üí User experience question
- API/integration prompts ‚Üí External dependencies question
- State/database prompts ‚Üí Data migration question
- TypeScript prompts ‚Üí Type safety question
- Default rotation (4 variations) - Are all relevant?

#### 3. Refinement Opportunities

Track these patterns over 2-4 weeks:

**Pattern 1: Irrelevant Questions**
- If a question consistently doesn't apply, adjust trigger keywords
- Example: If "External Dependencies" appears for non-API tasks, refine the regex pattern

**Pattern 2: Missing Questions**
- If important concerns aren't addressed, add new trigger keywords
- Example: If security concerns arise often without prompts, add security-focused questions

**Pattern 3: Threshold Tuning**
- Uncommitted files threshold (currently 15) - too high or too low?
- Critical items threshold (currently 5) - appropriate for your workflow?

#### 4. Keyword Refinement Log

Document trigger keyword effectiveness here:

```
Date: YYYY-MM-DD
Trigger: \b(api|service|integration)\b
Question: External Dependencies
Observations:
- Triggered appropriately: X times
- False positives: Y times
- Action: [Adjust/Keep/Remove]

Date: YYYY-MM-DD
Trigger: \b(ui|ux|interface)\b
Question: User Experience
Observations:
- Triggered appropriately: X times
- Missed opportunities: Y cases
- Action: [Add keywords/Adjust threshold]
```

#### 5. Recommended Adjustments

After monitoring, common refinements include:

**Add More Specific Triggers:**
```bash
# Security-focused prompts
elif echo "$PROMPT" | grep -qiE '\b(auth|security|crypto|password|token)\b'; then
  CONTEXT+="3. **Security**: Have you considered threat vectors and followed security best practices?"$'\n'
```

**Adjust Thresholds:**
```bash
# More aggressive uncommitted files warning
if [ "$UNCOMMITTED" -gt 10 ]; then  # Changed from 15
```

**Add Domain-Specific Variants:**
```bash
# Mobile-specific question
elif echo "$PROMPT" | grep -qiE '\b(mobile|ios|android|responsive)\b'; then
  CONTEXT+="3. **Mobile UX**: Does this work well on various screen sizes and orientations?"$'\n'
```

#### 6. Quick Feedback Loop

To test keyword changes:
```bash
# Test a specific prompt against the hook
export CLAUDE_PROJECT_DIR="$(pwd)"
echo '{"prompt": "YOUR TEST PROMPT HERE"}' | ./.claude/hooks/prompt-validator.sh | jq -r '.hookSpecificOutput.additionalContext' | grep -A 4 "Critical Reflection"
```

### Metrics to Track (Optional)

If you want quantitative data:
1. Questions asked per session (should be 3 every time)
2. Question relevance rating (1-5 scale, track manually)
3. Times you actually reconsidered approach due to question
4. False positive rate (questions that don't apply)

### Success Criteria

The questions are working well if:
- ‚úÖ They catch 80%+ of important considerations
- ‚úÖ False positive rate < 20%
- ‚úÖ You actually pause to think about them
- ‚úÖ They prevent real issues at least occasionally

### Next Review

Schedule first review: 2 weeks from deployment
- Review this document
- Analyze patterns
- Make 1-3 keyword/threshold adjustments
- Document changes in git commit

---

## Portability Summary

All hooks are **100% project-agnostic** and ready for use in any codebase:

| Hook | Portability | Languages Supported | Status |
|------|------------|---------------------|--------|
| validate-directory-creation.sh | 100% | All | ‚úÖ Production Ready |
| validate-markdown-creation.sh | 100% | All | ‚úÖ Production Ready |
| prompt-validator.sh | 100% | All | ‚úÖ Production Ready |
| session-start.sh | 100% | Node.js, Python, Go, Rust, Ruby, Java | ‚úÖ Production Ready |

### Quick Start for New Projects

1. Copy `.claude/hooks/` directory to your project
2. Ensure hooks are executable: `chmod +x .claude/hooks/*.sh`
3. Configure in `.claude/settings.json` (or let Claude Code auto-detect)
4. Restart Claude Code to activate

**That's it!** The hooks will automatically:
- Detect your project type (Node.js, Python, Go, Rust, Ruby, Java, etc.)
- Check dependencies and show relevant warnings
- Generate contextually appropriate reflection questions
- Enforce directory creation justification
- Restrict markdown file creation to approved locations
- Load project-specific guidelines from CLAUDE.md (if present)

### Testing Portability

Test the hooks work in different project types:

```bash
# Test in a Python project
cd /path/to/python-project
cp -r /path/to/these/hooks .claude/hooks
# Restart Claude Code

# Test in a Go project
cd /path/to/go-project
cp -r /path/to/these/hooks .claude/hooks
# Restart Claude Code
```

The hooks adapt automatically to each project's tech stack.

---

## Meta-Cognition Hook (Transcript Analysis)

### 5. Post-Tool Meta-Cognition
**File**: `posttooluse-metacognition.py`
**Triggers**: PostToolUse (all tools)
**Purpose**: Analyzes Claude's thinking patterns and tool usage to detect high-level reasoning gaps and missed opportunities

### 6. Pre-Tool Pattern Prevention
**File**: `pre-tool-pattern-prevention.sh`
**Triggers**: PreToolUse (all tools)
**Purpose**: Proactively prevents problematic tool usage before execution based on recent conversation patterns

---

## Meta-Cognition System

### Purpose
**Focuses on HIGH-LEVEL reasoning patterns, not syntax reminders.** This system detects when Claude:
- Claims things are impossible without checking available tools
- Hits problems without using Zen MCP or websearch
- Mentions tech without researching latest documentation
- Doesn't think "outside the box" or correlate complex systems

This is about **meta-cognitive awareness** - teaching Claude to recognize when it's missing opportunities.

### How It Works

**PostToolUse Hook** (Meta-Cognition Analysis):
- **Fast Path**: Checks tool name/response without transcript (tool-specific hints)
- **Slow Path**: Analyzes last 20 conversation turns for reasoning patterns
- Detects tool awareness gaps (Playwright, Zen MCP, WebSearch)
- Identifies meta-patterns (impossibility claims, uncertainty without research)
- Limits to top 3 hints to avoid overwhelming Claude

**PreToolUse Hook** (Policy Enforcement):
- Denies policy violations (e.g., WebFetch for browser interaction)
- Asks user approval for repeated TypeScript escape hatches
- Prevents mistakes before they happen

### Meta-Cognitive Patterns Detected

1. **Tool Awareness Gaps** (PostToolUse - REMINDER)
   - Mentions "manual testing" without Playwright MCP
   - Shows uncertainty without using Zen MCP
   - References tech versions without websearch
   - **Action**: Reminds about available tools

2. **Impossibility Claims** (PostToolUse - CHALLENGE)
   - Says "can't", "impossible", "requires manual" without verification
   - **Action**: Challenges to verify available tools first

3. **Uncertainty Without Research** (PostToolUse - SUGGESTION)
   - Says "I think", "probably", "maybe" without consulting resources
   - **Action**: Suggests websearch or Zen MCP consultation

4. **Missing Preventative Thinking** (PostToolUse - NUDGE)
   - Plans to test "after" or "later" instead of designing for testability
   - **Action**: Encourages proactive problem prevention

5. **WebFetch Misuse** (PreToolUse - DENY)
   - WebFetch + browser keywords ‚Üí Blocks and redirects to Playwright MCP
   - **Action**: Denies tool call, enforces Playwright MCP policy

6. **TypeScript Violations** (PreToolUse - ASK)
   - @ts-ignore/as any (repeated) ‚Üí Requests user approval
   - **Action**: Asks user to confirm or deny

### Performance
- **Target**: < 200ms per hook
- **Measured**: ~3-5ms per hook
- **Impact**: Zero user-facing delay (40x faster than target)

### Metrics & Monitoring

Pattern detections are logged to `.claude/hook-metrics.log` (if `CLAUDE_PROJECT_DIR` is set):

```
2025-11-02T12:34:56Z | PostToolUse | Read | repeated_errors (count: 3)
2025-11-02T12:35:10Z | PreToolUse | WebFetch | webfetch_misuse_denied
```

Use this log to track effectiveness and tune thresholds.

### Advanced Features

**Thinking Block Analysis** (Optional):
Uncomment the thinking block analysis section in `post-tool-self-correction.sh` to enable meta-level self-correction based on Claude's internal reasoning patterns:

- Detects low confidence ("I'm not sure", "uncertain")
- Identifies doubt patterns ("might not work", "let me try again")
- Provides additional context when Claude is uncertain

### Configuration

**Threshold Tuning**: Edit the hook scripts to adjust pattern thresholds:
- `ERROR_COUNT -ge 3` ‚Üí Number of repeated errors before blocking
- `MAX_REPETITION -ge 7` ‚Üí Circular tool usage threshold
- `CORRECTIONS -ge 2` ‚Üí User correction threshold
- `TS_VIOLATIONS -ge 1` ‚Üí TypeScript escape hatch threshold

**Pattern Addition**: Add new patterns by following existing pattern structure in hook scripts.

### Files
- `.claude/hooks/posttooluse-metacognition.py` - Meta-cognitive pattern detection (PostToolUse)
- `.claude/hooks/pre-tool-pattern-prevention.sh` - Proactive prevention (PreToolUse)
- `.claude/settings.json` - Hook configuration
- `.claude/hook-metrics.log` - Metrics logging (auto-created)

### Example Scenarios

**Scenario 1: Manual Testing Claim**
```
Claude: "We'll need to manually test the form validation in the browser..."
Hook detects: "testing" + "manual" + "browser" without Playwright mention
Output: "üé≠ Playwright MCP Available: You have mcp__playwright__* tools for browser automation..."
```

**Scenario 2: Uncertainty Without Research**
```
Claude: "I think the new Tailwind version might have breaking changes..."
Hook detects: "think" + "Tailwind version" without websearch
Output: "üîç WebSearch Available: You can search for latest documentation..."
```

**Scenario 3: Problem Without Investigation**
```
Claude encounters error, tries same approach 3 times
Hook detects: Repeated error pattern
Output: "üßò Zen MCP Available: Consider using debug tool for systematic root cause analysis..."
```

**Scenario 4: Agent/Skill Awareness**
```
Claude: "I need to update the player stats UI component..."
Hook detects: "ui" + "component" keywords match game-ui-designer agent
Output: "ü§ñ Agent Available: `game-ui-designer` - Expert in game UI/UX design and visual polish

üí° Delegate with: `Task(subagent_type="game-ui-designer", prompt="Your instructions")`"
```

**Scenario 5: Complex Multi-File Task**
```
Claude: "I'll modify the state management in GameState.ts, PlayerStats.tsx, InventorySystem.ts, SaveManager.ts, and LocalStorageHandler.ts..."
Hook detects: 5+ file mentions
Output: "üîÄ Complex Task Detected: Modifying 5+ files. Consider creating specialized agent:

üí° `Task(subagent_type="general-purpose", prompt="Specialized task description")`"
```

**Scenario 6: Parallelization Opportunity**
```
Claude: "First I'll update the types, then fix the tests, then update the docs, and then run the build..."
Hook detects: 4 sequential tasks ("then" patterns)
Output: "‚ö° Parallelization Opportunity: Multiple sequential tasks detected. Run them in parallel:

üí° Launch multiple Task agents simultaneously (up to 10 parallel)"
```

### Code Quality & Performance Detection (Phase 1)

**Added**: 2025-11-02

The meta-cognition hook now includes **code quality and performance anti-pattern detection** to catch maintainability issues and scalability problems early.

#### Code Quality Patterns (8 patterns)

1. **Long Method Detection** (>50 lines)
   - Suggests breaking into smaller functions
   - Example: "üìè **Long Method**: 85 lines detected. Consider breaking into smaller, focused functions (< 50 lines)."

2. **High Cyclomatic Complexity** (10+ conditionals)
   - Detects complex branching logic
   - Example: "üåÄ **High Complexity**: 15 conditionals detected. Consider simplifying logic or extracting functions."

3. **Deep Nesting** (>4 levels)
   - Identifies deeply nested code blocks
   - Example: "ü™Ü **Deep Nesting**: 6 levels detected. Consider extracting nested logic into separate functions."

4. **God Object/Class** (>500 lines)
   - Detects classes violating Single Responsibility Principle
   - Example: "üèõÔ∏è **God Object**: 750 line class. Consider splitting responsibilities (Single Responsibility Principle)."

5. **Missing Error Handling**
   - Finds try blocks without catch/except
   - Example: "‚ö†Ô∏è **Missing Error Handler**: Try block without catch/except clause. Add error handling."

6. **Debug Statements** (3+ console.log/print)
   - Catches debugging code left in production
   - Example: "üêõ **Debug Statements**: 5 console.log/print found. Remove before committing."

7. **Technical Debt Markers** (5+ TODO/FIXME)
   - Tracks accumulating technical debt
   - Example: "üìù **Technical Debt**: 8 TODO/FIXME markers. Consider addressing before adding more."

8. **Magic Numbers** (5+ numeric literals)
   - Suggests using named constants
   - Example: "üî¢ **Magic Numbers**: 7 numeric literals found. Consider using named constants."

#### Performance Anti-Patterns (6 patterns)

1. **N+1 Query Detection**
   - Identifies database/API calls inside loops
   - Example: "‚ö° **N+1 Query Detected**: Database/API call inside loop. Consider bulk fetching or caching."

2. **Nested Loops** (O(n¬≤) or O(n¬≥))
   - Detects algorithmic complexity issues
   - Example: "üîÑ **Nested Loops**: O(n¬≥) complexity detected. Consider using hash maps, sets, or better algorithms."

3. **String Concatenation in Loops**
   - Inefficient string building
   - Example: "üìù **String Concat in Loop**: Use array.join() or StringBuilder instead of += for better performance."

4. **Synchronous File Operations**
   - Blocking I/O detection
   - Example: "üêå **Blocking I/O**: 3 synchronous file operation(s). Consider async alternatives for non-blocking I/O."

5. **Repeated Expensive Calculations**
   - Missing memoization opportunities
   - Example: "üîÅ **Repeated Operations**: sort called 3 times. Consider caching/memoization."

6. **Object Creation in Loops**
   - Memory allocation inefficiency
   - Example: "üèóÔ∏è **Object Creation in Loop**: Creating objects/arrays in loop. Consider pre-allocation if size is known."

#### Performance Impact

- **Code quality checks**: ~5-10ms per Write/Edit operation
- **Performance checks**: ~5-10ms per Write/Edit operation
- **Total overhead**: ~10-20ms (acceptable for quality improvement)
- **Hint limiting**: Maximum 2 quality + 2 performance hints per tool call

#### Metrics Tracked

All patterns log to `.claude/hook-metrics.log`:
- `quality_long_method` - Long method detections
- `quality_high_complexity` - Complexity warnings
- `quality_deep_nesting` - Nesting level violations
- `quality_god_object` - God class detections
- `quality_missing_error_handler` - Missing error handling
- `quality_debug_statements` - Debug code left in
- `quality_tech_debt_markers` - TODO/FIXME accumulation
- `quality_magic_numbers` - Magic number usage
- `perf_n_plus_one` - N+1 query patterns
- `perf_nested_loops` - Nested loop complexity
- `perf_double_loop` - O(n¬≤) patterns
- `perf_string_concat_loop` - String concat inefficiency
- `perf_blocking_io` - Synchronous operations
- `perf_repeated_calculation` - Missing memoization
- `perf_object_creation_loop` - Loop allocation issues

#### Example Detections

**Code Quality:**
```python
# Long method with high complexity
def process_data(data):
    if condition1:
        if condition2:
            if condition3:
                if condition4:
                    if condition5:
                        # ... 60 more lines
                        pass
    # TODO: Refactor this
    # FIXME: Handle edge cases
    console.log(data)  # Debug statement
```
Output: "üìè **Long Method**: 65 lines detected..." + "üåÄ **High Complexity**: 12 conditionals..."

**Performance:**
```javascript
async function loadUserPosts(users) {
    for (const user of users) {
        const posts = await db.query(`SELECT * FROM posts WHERE userId = ${user.id}`);
        for (const post of posts) {
            for (const comment of post.comments) {
                result += comment.text;
            }
        }
    }
}
```
Output: "‚ö° **N+1 Query Detected**: Database call inside loop..." + "üîÑ **Nested Loops**: O(n¬≥) complexity..."

#### Configuration

**Adjust Thresholds** (in posttooluse-metacognition.py):
```python
# Line 260: Long method threshold
if lines > 50:  # Change to 75, 100, etc.

# Line 266: Complexity threshold
if conditionals > 10:  # Change to 15, 20, etc.

# Line 279: Nesting level threshold
if nesting_levels > 4:  # Change to 5, 6, etc.

# Line 285: God object threshold
if lines > 500:  # Change to 750, 1000, etc.
```

### Agent/Skill Awareness System

**Added**: 2025-11-02

The meta-cognition hook now includes **agent and skill awareness** to help Claude recognize when to delegate work to specialized agents or create reusable skills.

#### Features

**1. Existing Agent Discovery**
- Automatically scans `.claude/agents/*.md` at startup (cached for performance)
- Extracts agent descriptions from frontmatter
- Matches conversation patterns to suggest relevant agents

**Domain-Specific Agent Triggers:**
- **UI/UX work** ‚Üí `game-ui-designer`
- **Entity creation** ‚Üí `entity-creator`
- **State/localStorage issues** ‚Üí `state-debugger`
- **TypeScript errors** ‚Üí `strict-typescript-enforcer`
- **Game balance** ‚Üí `game-balance-auditor`
- **AI integration** ‚Üí `ai-integration-specialist`

**2. Complexity-Based Agent Creation Suggestions**
- **5+ files being modified** ‚Üí Suggest creating specialized agent
- **3+ sequential tasks** ‚Üí Suggest parallel agent execution
- Helps Claude recognize when task complexity justifies delegation

**3. Skill Awareness**
- Automatically scans `.claude/skills/` directories
- Suggests skill creation for repeated workflows
- Lists available skills when patterns detected

**4. Smart Filtering**
- **Skips suggestions** if Claude is already using Task tool (avoids redundancy)
- **Limits to 1 suggestion** per tool call (avoids overwhelming)
- **Cached directory scan** (5-10ms one-time cost, not per-call)

#### Performance Impact

- **Discovery**: ~5-10ms (one-time, cached globally)
- **Pattern matching**: ~2-5ms per tool call
- **Total overhead**: ~7-15ms (negligible, well within budget)

#### Effectiveness Metrics

Track these metrics in `.claude/hook-metrics.log`:
- `agent_skill_discovery` - Number of agents/skills found at startup
- `agent_match_{agent_name}` - Domain-specific agent suggestions
- `complex_multi_file` - Complex task detections
- `parallelization_opportunity` - Parallelization suggestions
- `repeated_workflow` - Skill creation suggestions

**Target Impact:**
- Agent utilization: 5% ‚Üí 30% (expected increase)
- Better task parallelization for complex multi-step work
- More consistent use of skills for repeated patterns

#### Configuration

**Adjust File Threshold:**
```python
# In detect_agent_opportunities()
if file_mentions >= 5:  # Change this threshold
```

**Adjust Parallelization Threshold:**
```python
# In detect_agent_opportunities()
if task_markers >= 3:  # Change this threshold
```

**Add Custom Agent Patterns:**
```python
# In agent_patterns dict
"your-agent-name": r"\b(keyword1|keyword2|pattern)\b"
```

#### Monitoring

After 2-4 weeks of usage, review metrics to assess:
- **Relevance**: Are agent suggestions helpful?
- **False positives**: Are suggestions triggered inappropriately?
- **Utilization**: Is Claude actually using suggested agents?

Adjust thresholds based on data.

### Troubleshooting

**Hooks not firing:**
1. Restart Claude Code (hooks are loaded at startup)
2. Check `/hooks` menu to verify registration
3. Use `claude --debug` to see hook execution details

**False positives:**
1. Increase thresholds in hook scripts
2. Review `.claude/hook-metrics.log` for patterns
3. Adjust after 50+ detections based on effectiveness

**Performance issues:**
- Hooks run in parallel (all matching hooks execute simultaneously)
- 10s timeout per hook (configurable)
- Gracefully degrades if jq is missing

### Testing

Test the hooks manually:

```bash
# Simulate PostToolUse with repeated error
echo '{"transcript_path": "~/.claude/projects/.../session.jsonl", "tool_name": "Read", "tool_response": {"error": "File not found"}}' | \
  ./.claude/hooks/post-tool-self-correction.sh

# Simulate PreToolUse with WebFetch
echo '{"transcript_path": "~/.claude/projects/.../session.jsonl", "tool_name": "WebFetch", "tool_input": {"url": "example.com"}}' | \
  ./.claude/hooks/pre-tool-pattern-prevention.sh
```

### Best Practices

1. **Start Conservative**: Use default thresholds, monitor effectiveness for 2-4 weeks
2. **Track Metrics**: Enable logging to understand pattern frequency
3. **Iterate Based on Data**: Adjust thresholds after gathering real-world usage data
4. **User Feedback**: After 50 detections, evaluate if patterns are helpful or noisy
5. **Gradual Rollout**: Test in development before production use

### Portability

‚úÖ **100% Project-Agnostic**
- Works in any codebase without modification
- Auto-detects patterns regardless of language or framework
- No dependencies beyond `jq` (with graceful degradation)
- Portable across all Claude Code installations

**To use in a different project:**
```bash
# Copy hooks to new project
cp .claude/hooks/post-tool-self-correction.sh /path/to/other/project/.claude/hooks/
cp .claude/hooks/pre-tool-pattern-prevention.sh /path/to/other/project/.claude/hooks/

# Ensure executable
chmod +x /path/to/other/project/.claude/hooks/*.sh

# Update settings.json with hook configuration
# Restart Claude Code - hooks activate automatically
```

---

---

## Tool Planning Hook - Phase 1.5 & 2 (Enhanced Patterns + Zen MCP Infrastructure)

**Status:** Phase 1.5 Deployed, Phase 2 Infrastructure Ready  
**Date:** 2025-11-11

### Overview

The tool planning system has been upgraded from basic pattern matching (Phase 1 MVP) to a **three-tier graduated escalation system** that provides production-grade optimization recommendations.

### Three-Tier Architecture

```
USER PROMPT ‚Üí [Tier-0: Classifier] ‚Üí atomic (SKIP)
                                    ‚Üí routine (Tier-1: 3s)
                                    ‚Üí complex (Tier-1.5: 5s)
                                    ‚Üí risky ‚Üí Escalation Decision
                                    |           ‚Üí High risk: Tier-2 (15s) ‚Üí [fallback] Tier-1.5
                                    |           ‚Üí Low risk: Tier-1.5 (5s)
                                    ‚Üí open_world ‚Üí Tier-2 (15s) ‚Üí [fallback] Tier-1.5
```

**Tier-1**: Basic patterns (parallelization, scripts, MCP tools, agents)  
**Tier-1.5**: Enhanced patterns (API, database, security, state, error handling)  
**Tier-2**: Zen MCP deep planning (safety, research, strategic analysis)

### Phase 1.5: Enhanced Pattern Detection

**New Patterns (19 total):**

**API Optimization (4 patterns):**
1. üåê Rate limiting detection
2. üåê Batch request opportunities
3. üåê Caching recommendations
4. üåê Retry logic for external APIs

**Database Optimization (4 patterns):**
1. üóÑÔ∏è N+1 query detection
2. üóÑÔ∏è Transaction safety
3. üóÑÔ∏è Bulk operation suggestions
4. üóÑÔ∏è Index awareness

**Security (5 patterns):**
1. üîí Auth/authorization audit recommendations
2. üîí Input validation requirements
3. üîí Credential management
4. üîí SQL injection prevention
5. üîí XSS prevention

**State Management (3 patterns):**
1. üìä Atomic state updates
2. üìä Concurrency control
3. üìä Rollback strategies

**Error Handling (3 patterns):**
1. üõ°Ô∏è External operation resilience
2. üõ°Ô∏è Retry logic with exponential backoff
3. üõ°Ô∏è Fallback behavior for critical paths

**Files:**
- `.claude/hooks/lib/enhanced_patterns.py` (370 lines, 5 detection functions)
- `.claude/hooks/lib/quick_tool_planner.py` (updated with Tier-1.5 integration)
- `.claude/hooks/tests/test_enhanced_patterns.py` (23 unit tests, 100% pass)

**Performance:**
- Complex tasks: ~3-4s (target: < 5s) ‚úÖ
- Risky tasks: ~3-4s (target: < 5s) ‚úÖ
- 7 recommendations max (sorted by confidence boost)

### Phase 2: Zen MCP Infrastructure

**Purpose:** Deep strategic planning for high-risk and research tasks

**Escalation Logic:**
```bash
# Always use Zen MCP for research
open_world ‚Üí Tier-2

# Use Zen MCP for high-severity risky tasks
risky + (production|deploy|migration|database drop|payment) ‚Üí Tier-2
risky (other) ‚Üí Tier-1.5
```

**Components:**

**Context Gatherer** (`lib/context_gatherer.sh`):
- Lightweight project detection (< 500ms)
- Auto-detects: Node.js, Python, Go, Rust, Ruby, Java
- Gathers: project type, package manager, file counts, git status
- Runs in parallel for speed

**Zen Tool Planner** (`lib/zen_tool_planner.py`):
- Invokes `mcp__zen__planner` with structured prompt
- 12s timeout with graceful fallback to Tier-1.5
- 15-minute cache (separate from Tier-1 cache)
- Currently: Placeholder implementation (returns None ‚Üí triggers fallback)

**Escalation in tool-planner.sh:**
- `should_use_zen_mcp()` function determines escalation
- Gathers context, invokes Zen MCP, falls back on failure
- Adds risky task warning footer

**Current Status:**
- ‚úÖ Infrastructure fully implemented
- üü° Placeholder MCP integration (ready for production when needed)
- ‚úÖ Fallback to Tier-1.5 tested and working

**Example Output (Tier-2 fallback):**
```
## üõ†Ô∏è Tool Strategy (Auto-Generated)

**Task Class:** risky | **Planning Tier:** 1.5 (enhanced patterns - API/DB/Security)

**Recommended Optimizations:**
1. üóÑÔ∏è **Database Optimization**: N+1 query pattern detected...
2. üåê **Api Optimization**: Loop + API call detected...
3. üîí **Security**: Authentication code - recommend zen:codereview...

**Estimated Time Savings:** ~490s
**Confidence Boost:** +0.67 (via tooling_optimization_score)

‚ö†Ô∏è **RISKY TASK**: Consider creating backup or dry-run strategy before proceeding.
```

### Testing

**Unit Tests:**
```bash
# Run Phase 1.5 enhanced pattern tests
python3 ./.claude/hooks/tests/test_enhanced_patterns.py
# Result: 23/23 tests passed ‚úÖ
```

**Integration Tests:**
```bash
# Test Tier-1.5 (complex task with security)
echo '{"prompt": "Implement user authentication with password validation"}' | \
  ./.claude/hooks/tool-planner.sh

# Test escalation (high-risk risky)
echo '{"prompt": "Deploy to production and migrate database"}' | \
  ./.claude/hooks/tool-planner.sh

# Test N+1 query detection
echo '{"prompt": "Loop through users and fetch posts from API then update database"}' | \
  ./.claude/hooks/tool-planner.sh
```

### Performance Metrics

| Tier | Task Class | Target | Actual | Status |
|------|-----------|--------|--------|--------|
| 0 | All | < 50ms | ~30ms | ‚úÖ Met |
| 1 | Routine | < 3s | ~2s | ‚úÖ Met |
| 1.5 | Complex, Risky (low) | < 5s | ~3-4s | ‚úÖ Met |
| 2 | Risky (high), Open World | < 15s | N/A | üü° Ready |

### Disabling/Rollback

**Disable Tier-1.5 (revert to Tier-1):**
```bash
# Remove enhanced_patterns.py
rm .claude/hooks/lib/enhanced_patterns.py
# System automatically falls back to Tier-1
```

**Disable Tier-2 (revert to Tier-1.5 max):**
```bash
# Edit tool-planner.sh: should_use_zen_mcp()
# Change all return 0 to return 1
```

**Complete Rollback to Phase 1 MVP:**
```bash
git revert <phase-1.5-commit>
```

### Future: Phase 3 (Learning Loop)

**Not Yet Implemented** - Planned features:

1. **Outcome Logging**
   - Track which tools were actually used
   - Log to `.claude/tool_planning_outcomes.jsonl`
   - Calculate plan adherence (Jaccard similarity)

2. **Weekly Analysis**
   - Pattern effectiveness (success rate per pattern)
   - Time estimate accuracy
   - Confidence boost correlation

3. **Feedback Loop**
   - Adjust pattern weights based on outcomes
   - Suppress ineffective patterns (< 30% success)
   - Generate few-shot examples for Zen MCP
   - Update `.claude/tool_plan_config.json`

**Implementation Timeline:** Week 6-8 (per original plan)

### Documentation

- **ADR-TP002**: Complete architecture documentation in `docs/ADR.md`
- **Implementation Plan**: Comprehensive 8-week rollout plan (see previous conversation)
- **Test Coverage**: 23 unit tests with 100% pass rate

### Monitoring

Watch for these patterns over 2-4 weeks:
- Pattern relevance (false positive rate)
- Suggestion usefulness (qualitative feedback)
- Performance overhead (hook execution time)
- Fallback frequency (Tier-2 ‚Üí Tier-1.5)

### Related Hooks

- **confidence-classifier.sh**: Provides task classification for Tier-0
- **posttooluse-metacognition.py**: Future integration point for outcome tracking (Phase 3)


---

## Zen MCP Integration - Production Implementation (2025-11-11)

**Status:** ‚úÖ Production Ready (CLI-based subprocess invocation)

The Zen MCP placeholder has been replaced with a production-ready implementation using the Claude CLI.

### Implementation Method

**Architecture:** Subprocess-based MCP invocation via `claude` CLI

```python
# Command: claude tool mcp__zen__planner -i -
command = ["claude", "tool", "mcp__zen__planner", "-i", "-"]

result = subprocess.run(
    command,
    input=zen_prompt_json,  # JSON via stdin
    capture_output=True,
    text=True,
    timeout=12,
    check=True  # Raises CalledProcessError on failure
)
```

**Why This Approach:**
- Stable, public `claude` CLI interface (recommended pattern per Zen MCP research)
- Automatic authentication handling
- Insulated from MCP protocol changes
- No manual HTTP/IPC or token management

### Input Schema

Zen MCP planner expects JSON via stdin:

```json
{
  "step": "planning prompt with context and requirements",
  "step_number": 1,
  "total_steps": 1,
  "next_step_required": false,
  "findings": "Tool planning for risky task",
  "model": "google/gemini-2.5-pro"
}
```

### Error Handling & Fallback

**Four Failure Modes:**
1. `FileNotFoundError` - Claude CLI not in PATH ‚Üí Fallback to Tier-1.5
2. `TimeoutExpired` - 12s timeout exceeded ‚Üí Fallback to Tier-1.5
3. `CalledProcessError` - Tool execution failed ‚Üí Fallback to Tier-1.5
4. Generic exceptions ‚Üí Fallback to Tier-1.5

All errors logged to stderr (doesn't interfere with hook JSON output)

### Testing

**Unit Test (JSON structure):**
```bash
python3 -c "
from zen_tool_planner import build_zen_prompt
result = build_zen_prompt('Deploy to production', 'risky', {'project_type': 'nodejs'})
import json
parsed = json.loads(result)  # Validates JSON structure
print('Keys:', list(parsed.keys()))
"
# Output: Keys: ['step', 'step_number', 'total_steps', 'next_step_required', 'findings', 'model']
```

**Integration Test (requires claude CLI):**
```bash
# High-risk task should trigger Zen MCP
echo '{"prompt": "Deploy to production and migrate database"}' | \
  ./.claude/hooks/tool-planner.sh

# Expected behavior:
# 1. Detects "production" + "migration" ‚Üí should_use_zen_mcp() = true
# 2. Attempts: claude tool mcp__zen__planner -i -
# 3. If CLI available: Returns Tier-2 Zen MCP analysis
# 4. If CLI unavailable: Falls back to Tier-1.5 enhanced patterns
```

### Deployment Requirements

**Required:**
- `claude` CLI must be in PATH during hook execution
- Hooks run in subprocess - ensure PATH includes CLI location

**Optional:**
- stderr logging for debugging (automatically enabled)

**Verification:**
```bash
# Check if claude CLI available
which claude
# Should return: /path/to/claude

# Test basic CLI invocation
echo '{"step": "test", "step_number": 1, "total_steps": 1, "next_step_required": false, "findings": "test", "model": "google/gemini-2.5-pro"}' | \
  claude tool mcp__zen__planner -i -
# Should return: Zen MCP analysis or error
```

### Monitoring

**Log Location:** stderr (doesn't interfere with hook JSON output)

**Log Format:**
```
2025-11-11 06:30:00 - zen_planner - INFO - Invoking Zen MCP planner (timeout: 12s)
2025-11-11 06:30:05 - zen_planner - INFO - Zen MCP planner call successful
```

**Failure Scenarios:**
```
# CLI not found
2025-11-11 06:30:00 - zen_planner - ERROR - Claude CLI not found. Ensure 'claude' command is in PATH. Falling back to Tier-1.5.

# Timeout
2025-11-11 06:30:12 - zen_planner - WARNING - Zen MCP planner timed out after 12s. Falling back to Tier-1.5.

# Tool failure
2025-11-11 06:30:05 - zen_planner - ERROR - Zen MCP planner failed with exit code 1. Stderr: [error details]
```

### Performance

**Tier-2 Budget:** < 15s total
- Context gathering: ~500ms
- Zen MCP invocation: 12s timeout
- Parsing/formatting: ~500ms
- **Total:** ~13s (within budget)

**Fallback Performance:**
- Tier-1.5: ~3-4s (if Zen MCP fails)
- No user-facing delay on fallback

### Production Readiness

- ‚úÖ CLI-based subprocess invocation
- ‚úÖ JSON schema validated
- ‚úÖ Timeout enforcement (12s)
- ‚úÖ Comprehensive error handling
- ‚úÖ Graceful fallback
- ‚úÖ Logging for debugging
- ‚úÖ No hardcoded credentials
- ‚úÖ Compatible with hook environment

**Status:** Ready for production when `claude` CLI is available in hook PATH.

